{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from  torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "# import pydicom\n",
    "import timm #from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from sklearn.metrics import log_loss\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_labels = pd.read_csv('/home/thinh/nfl/train_labels.csv')\n",
    "# video_labels = video_labels[video_labels['frame'] != 0].reset_index(drop=True)\n",
    "# video_labels['image_name'] = video_labels['video'].str.replace('.mp4', '') + '_' + video_labels['frame'].astype(str) + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df, data_root, transforms=None, output_label=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.df.iloc[index]['label']\n",
    "          \n",
    "        path = \"{}/{}\".format(self.data_root, self.df.iloc[index]['image_id'])\n",
    "        \n",
    "        img  = get_img(path)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "            \n",
    "        # do label smoothing\n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Validation Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_transforms():\n",
    "    return A.Compose([\n",
    "            A.RandomResizedCrop(512, 512),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_one_model(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        \n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [02:42<00:00,  4.03it/s]\n",
      "100%|██████████| 653/653 [02:47<00:00,  3.90it/s]\n",
      "100%|██████████| 653/653 [02:56<00:00,  3.71it/s]\n",
      "100%|██████████| 653/653 [02:58<00:00,  3.66it/s]\n",
      "100%|██████████| 653/653 [03:02<00:00,  3.58it/s]\n",
      "100%|██████████| 653/653 [03:07<00:00,  3.48it/s]\n",
      "100%|██████████| 653/653 [03:06<00:00,  3.49it/s]\n",
      "100%|██████████| 653/653 [03:10<00:00,  3.42it/s]\n",
      "100%|██████████| 653/653 [03:09<00:00,  3.44it/s]\n",
      "100%|██████████| 653/653 [03:11<00:00,  3.41it/s]\n",
      "100%|██████████| 653/653 [03:08<00:00,  3.47it/s]\n",
      "100%|██████████| 653/653 [03:08<00:00,  3.47it/s]\n",
      "100%|██████████| 653/653 [03:08<00:00,  3.46it/s]\n",
      "100%|██████████| 653/653 [03:08<00:00,  3.46it/s]\n",
      "100%|██████████| 653/653 [03:13<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT_PATH = '/home/thinh/nfl/train_images/'\n",
    "test = pd.DataFrame()\n",
    "test['image_id'] = list(os.listdir(f'{DATA_ROOT_PATH}'))\n",
    "video_valid = ['57583_000082', '57586_004152', '57911_000147', '57997_003691', '57680_002206', '58095_004022', '57906_000718', '58005_001254', '57679_003316', '58103_003494', '57998_002181', '58048_000086']\n",
    "test = test[test['image_id'].apply(lambda x: \"_\".join(x.split('_')[:2])).isin(video_valid)]\n",
    "\n",
    "test_ds = CassavaDataset(test, f'{DATA_ROOT_PATH}', transforms=get_inference_transforms(), output_label=False)\n",
    "# image_ids=np.array([path.split('/')[-1] for path in glob(f'{DATA_ROOT_PATH}/*.png')]),\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "            test_ds, \n",
    "            batch_size=16,\n",
    "            num_workers=8,\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "\n",
    "model_imgs = ['/home/thinh/nfl/frame-models/tf_efficientnet_b4_ns_512_fold_0_0',\n",
    "              '/home/thinh/nfl/frame-models/tf_efficientnet_b4_ns_512_fold_1_0',\n",
    "              '/home/thinh/nfl/frame-models/tf_efficientnet_b4_ns_512_fold_2_0',\n",
    "              '/home/thinh/nfl/frame-models/tf_efficientnet_b4_ns_512_fold_3_0',\n",
    "              '/home/thinh/nfl/frame-models/tf_efficientnet_b4_ns_512_fold_4_0',\n",
    "             ]\n",
    "\n",
    "tst_preds = []\n",
    "for model_img in model_imgs:\n",
    "    model = CassvaImgClassifier('tf_efficientnet_b4_ns', 2).to(device)\n",
    "    model.load_state_dict(torch.load(model_img, map_location='cuda:0'))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(3):\n",
    "            tst_preds += [inference_one_model(model, tst_loader)]\n",
    "            \n",
    "tst_preds = np.mean(tst_preds, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3326, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>frame</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>57680_002206_Sideline.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>57679_003316_Endzone.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>57583_000082_Endzone.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>57586_004152_Sideline.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>57997_003691_Endzone.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  frame                      video\n",
       "14       1    141  57680_002206_Sideline.mp4\n",
       "45       1    158   57679_003316_Endzone.mp4\n",
       "68       1    120   57583_000082_Endzone.mp4\n",
       "69       1     42  57586_004152_Sideline.mp4\n",
       "104      1    136   57997_003691_Endzone.mp4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.DataFrame()\n",
    "# test['image_id'] = list(os.listdir(f'{DATA_ROOT_PATH}'))\n",
    "test['label'] = np.argmax(tst_preds, axis=1)\n",
    "test = test[test.label == 1]\n",
    "test['frame'] = test.image_id.str.split('_').str[3].str.replace('.png','').astype(int)\n",
    "test['video'] = test.image_id.str.rsplit('_',1).str[0] + '.mp4'\n",
    "test = test.drop(columns=['image_id'])\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('frame_impact_512.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
