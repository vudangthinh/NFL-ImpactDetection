{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_paths = [\n",
    "    'FMix-master'\n",
    "]\n",
    "import sys; \n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "from fmix import sample_mask, make_low_freq_image, binarise_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'img_size': 720,\n",
    "    'epochs': 2,\n",
    "    'train_bs': 8,\n",
    "    'valid_bs': 16,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay':1e-6,\n",
    "    'num_workers': 4,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:1'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_labels = pd.read_csv('/home/thinh/nfl/train_labels.csv').fillna(0)\n",
    "# video_labels = video_labels[video_labels['frame'] != 0].reset_index(drop=True)\n",
    "# video_labels['video_name'] = video_labels['video'].apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n",
    "# video_valid = ['57583_000082', '57586_004152', '57911_000147', '57997_003691', '57680_002206', '58095_004022', '57906_000718', '58005_001254', '57679_003316', '58103_003494', '57998_002181', '58048_000086']\n",
    "# video_labels = video_labels[~video_labels.video_name.isin(video_valid)]\n",
    "\n",
    "# video_labels_with_impact = video_labels[video_labels['impact'] > 0]\n",
    "# for row in tqdm(video_labels_with_impact[['video','frame','label']].values):\n",
    "#     frames = np.array([-4,-3,-2,-1,1,2,3,4])+row[1]\n",
    "#     video_labels.loc[(video_labels['video'] == row[0]) \n",
    "#                                  & (video_labels['frame'].isin(frames))\n",
    "#                                  & (video_labels['label'] == row[2]), 'impact'] = 1\n",
    "\n",
    "\n",
    "# video_labels['image_name'] = video_labels['video'].str.replace('.mp4', '') + '_' + video_labels['frame'].astype(str) + '.png'\n",
    "# video_labels.to_csv('frame_train_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57584_000336_Endzone_1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57584_000336_Endzone_10.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57584_000336_Endzone_100.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57584_000336_Endzone_101.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57584_000336_Endzone_102.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image_id  label\n",
       "0    57584_000336_Endzone_1.png      0\n",
       "1   57584_000336_Endzone_10.png      0\n",
       "2  57584_000336_Endzone_100.png      0\n",
       "3  57584_000336_Endzone_101.png      0\n",
       "4  57584_000336_Endzone_102.png      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_labels = pd.read_csv('frame_train_labels.csv')\n",
    "train = video_labels.groupby('image_name')['impact'].sum().reset_index()\n",
    "train['impact'] = train['impact'].apply(lambda x: 1 if x > 0 else 0)\n",
    "train.columns = ['image_id', 'label']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id_label_0 = train[train['label'] == 0].image_id.tolist()\n",
    "image_id_label_1 = train[train['label'] == 1].image_id.tolist()\n",
    "image_id_label_0 = random.sample(image_id_label_0, 10000)\n",
    "image_ids = image_id_label_0 + image_id_label_1\n",
    "\n",
    "train = train[train.image_id.isin(image_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10000\n",
       "1     8004\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['group'] = train['image_id'].apply(lambda x: \"_\".join(x.split('_')[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            CoarseDropout(p=0.5),\n",
    "            Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, data_root, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                 one_hot_label=False,\n",
    "                 do_fmix=False, \n",
    "                 fmix_params={\n",
    "                     'alpha': 1., \n",
    "                     'decay_power': 3., \n",
    "                     'shape': (CFG['img_size'], CFG['img_size']),\n",
    "                     'max_soft': True, \n",
    "                     'reformulate': False\n",
    "                 },\n",
    "                 do_cutmix=False,\n",
    "                 cutmix_params={\n",
    "                     'alpha': 1,\n",
    "                 }\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.do_fmix = do_fmix\n",
    "        self.fmix_params = fmix_params\n",
    "        self.do_cutmix = do_cutmix\n",
    "        self.cutmix_params = cutmix_params\n",
    "        \n",
    "        self.output_label = output_label\n",
    "        self.one_hot_label = one_hot_label\n",
    "        \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "            #print(self.labels)\n",
    "            \n",
    "            if one_hot_label is True:\n",
    "                self.labels = np.eye(self.df['label'].max()+1)[self.labels]\n",
    "                #print(self.labels)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "          \n",
    "        img = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        if self.do_fmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n",
    "            with torch.no_grad():\n",
    "                #lam, mask = sample_mask(**self.fmix_params)\n",
    "                \n",
    "                lam = np.clip(np.random.beta(self.fmix_params['alpha'], self.fmix_params['alpha']),0.6,0.7)\n",
    "                \n",
    "                # Make mask, get mean / std\n",
    "                mask = make_low_freq_image(self.fmix_params['decay_power'], self.fmix_params['shape'])\n",
    "                mask = binarise_mask(mask, lam, self.fmix_params['shape'], self.fmix_params['max_soft'])\n",
    "    \n",
    "                fmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                fmix_img  = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[fmix_ix]['image_id']))\n",
    "\n",
    "                if self.transforms:\n",
    "                    fmix_img = self.transforms(image=fmix_img)['image']\n",
    "\n",
    "                mask_torch = torch.from_numpy(mask)\n",
    "                \n",
    "                # mix image\n",
    "                img = mask_torch*img+(1.-mask_torch)*fmix_img\n",
    "\n",
    "                #print(mask.shape)\n",
    "\n",
    "                #assert self.output_label==True and self.one_hot_label==True\n",
    "\n",
    "                # mix target\n",
    "                rate = mask.sum()/CFG['img_size']/CFG['img_size']\n",
    "                target = rate*target + (1.-rate)*self.labels[fmix_ix]\n",
    "                #print(target, mask, img)\n",
    "                #assert False\n",
    "        \n",
    "        if self.do_cutmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n",
    "            #print(img.sum(), img.shape)\n",
    "            with torch.no_grad():\n",
    "                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                cmix_img  = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[cmix_ix]['image_id']))\n",
    "                if self.transforms:\n",
    "                    cmix_img = self.transforms(image=cmix_img)['image']\n",
    "                    \n",
    "                lam = np.clip(np.random.beta(self.cutmix_params['alpha'], self.cutmix_params['alpha']),0.3,0.4)\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox((CFG['img_size'], CFG['img_size']), lam)\n",
    "\n",
    "                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "                rate = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (CFG['img_size'] * CFG['img_size']))\n",
    "                target = rate*target + (1.-rate)*self.labels[cmix_ix]\n",
    "                \n",
    "            #print('-', img.sum())\n",
    "            #print(target)\n",
    "            #assert False\n",
    "                            \n",
    "        # do label smoothing\n",
    "        #print(type(img), type(target))\n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root='/home/thinh/nfl/train_images/'):\n",
    "    \n",
    "#     from catalyst.data.sampler import BalanceClassSampler\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "        \n",
    "    train_ds = CassavaDataset(train_, \n",
    "                              data_root, \n",
    "                              transforms=get_train_transforms(), \n",
    "                              output_label=True, \n",
    "                              one_hot_label=False, \n",
    "                              do_fmix=False, \n",
    "                              do_cutmix=False)\n",
    "    valid_ds = CassavaDataset(valid_, \n",
    "                              data_root, \n",
    "                              transforms=get_valid_transforms(), \n",
    "                              output_label=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
    "    model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "\n",
    "        #print(image_labels.shape, exam_label.shape)\n",
    "        with autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "            #print(image_preds.shape, exam_pred.shape)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                \n",
    "                pbar.set_description(description)\n",
    "                \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()\n",
    "        \n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        #print(image_preds.shape, exam_pred.shape)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]  \n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "            pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    print(np.unique(image_preds_all, return_counts=True))\n",
    "    print(np.unique(image_targets_all, return_counts=True))\n",
    "    print('validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
    "    print('recall = {:.4f}'.format(recall_score(image_targets_all, image_preds_all)))\n",
    "    print('precision = {:.4f}'.format(precision_score(image_targets_all, image_preds_all)))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733\n",
    "class MyCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean'):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n",
      "14563 3441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.6178: 100%|█████████▉| 1820/1821 [48:47<00:01,  1.61s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.64 GiB (GPU 1; 10.92 GiB total capacity; 3.25 GiB already allocated; 3.64 GiB free; 6.60 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7992147a43e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschd_batch_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-605763fe3f81>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, loss_fn, optimizer, train_loader, device, scheduler, schd_batch_update)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#print(image_labels.shape, exam_label.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mimage_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#output = model(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;31m#print(image_preds.shape, exam_pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-efdefc1bcd78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         '''\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/timm/models/efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# Point-wise linear projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_pwl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.64 GiB (GPU 1; 10.92 GiB total capacity; 3.25 GiB already allocated; 3.64 GiB free; 6.60 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    folds = GroupKFold(n_splits=CFG['fold_num']).split(np.arange(train.shape[0]), train.label.values, train.group.values)\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # we'll train fold 0 first\n",
    "#         if fold > 0:\n",
    "#             break \n",
    "\n",
    "        print('Training with {} started'.format(fold))\n",
    "\n",
    "        print(len(trn_idx), len(val_idx))\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='/home/thinh/nfl/train_images/')\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        \n",
    "        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique(), pretrained=True).to(device)\n",
    "        scaler = GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "        #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=CFG['epochs']-1)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n",
    "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=25, \n",
    "        #                                                max_lr=CFG['lr'], epochs=CFG['epochs'], steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        for epoch in range(CFG['epochs']):\n",
    "            train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "\n",
    "            torch.save(model.state_dict(),'/home/thinh/nfl/frame-models/{}_1024_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n",
    "            \n",
    "        #torch.save(model.cnn_model.state_dict(),'{}/cnn_model_fold_{}_{}'.format(CFG['model_path'], fold, CFG['tag']))\n",
    "        \n",
    "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "        with torch.cuda.device(CFG['device']):\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with 0 started\n",
    "# 2777 695\n",
    "# epoch 0 loss: 0.6624: 100%|██████████| 174/174 [04:38<00:00,  1.60s/it]\n",
    "# epoch 0 loss: 0.6424: 100%|██████████| 22/22 [00:13<00:00,  1.63it/s]\n",
    "# (array([0, 1]), array([487, 208]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.5669\n",
    "# epoch 1 loss: 0.6275: 100%|██████████| 174/174 [04:44<00:00,  1.63s/it]\n",
    "# epoch 1 loss: 0.6427: 100%|██████████| 22/22 [00:12<00:00,  1.70it/s]\n",
    "# (array([0, 1]), array([391, 304]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6158\n",
    "# epoch 2 loss: 0.6086: 100%|██████████| 174/174 [04:46<00:00,  1.65s/it]\n",
    "# epoch 2 loss: 0.6374: 100%|██████████| 22/22 [00:11<00:00,  1.90it/s]\n",
    "# (array([0, 1]), array([506, 189]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6288\n",
    "# epoch 3 loss: 0.6281: 100%|██████████| 174/174 [04:42<00:00,  1.62s/it]\n",
    "# epoch 3 loss: 0.6487: 100%|██████████| 22/22 [00:11<00:00,  1.92it/s]\n",
    "# (array([0, 1]), array([498, 197]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6374\n",
    "# epoch 4 loss: 0.5527: 100%|██████████| 174/174 [04:44<00:00,  1.64s/it]\n",
    "# epoch 4 loss: 0.6521: 100%|██████████| 22/22 [00:11<00:00,  1.89it/s]\n",
    "# (array([0, 1]), array([337, 358]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6475\n",
    "# epoch 5 loss: 0.5262: 100%|██████████| 174/174 [04:45<00:00,  1.64s/it]\n",
    "# epoch 5 loss: 0.6504: 100%|██████████| 22/22 [00:11<00:00,  1.91it/s]\n",
    "# (array([0, 1]), array([339, 356]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6417\n",
    "# epoch 6 loss: 0.5045: 100%|██████████| 174/174 [04:45<00:00,  1.64s/it]\n",
    "# epoch 6 loss: 0.6450: 100%|██████████| 22/22 [00:11<00:00,  1.92it/s]\n",
    "# (array([0, 1]), array([337, 358]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6388\n",
    "# epoch 7 loss: 0.5159: 100%|██████████| 174/174 [04:46<00:00,  1.64s/it]\n",
    "# epoch 7 loss: 0.6613: 100%|██████████| 22/22 [00:11<00:00,  1.86it/s]\n",
    "# (array([0, 1]), array([414, 281]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6403\n",
    "# epoch 8 loss: 0.5050: 100%|██████████| 174/174 [04:46<00:00,  1.65s/it]\n",
    "# epoch 8 loss: 0.6582: 100%|██████████| 22/22 [00:12<00:00,  1.69it/s]\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6460\n",
    "# epoch 9 loss: 0.4887: 100%|██████████| 174/174 [04:46<00:00,  1.65s/it]\n",
    "# epoch 9 loss: 0.6603: 100%|██████████| 22/22 [00:12<00:00,  1.69it/s]\n",
    "# (array([0, 1]), array([419, 276]))\n",
    "# (array([0, 1]), array([400, 295]))\n",
    "# validation multi-class accuracy = 0.6446\n",
    "\n",
    "\n",
    "# Training with 0 started\n",
    "# 16013 4004\n",
    "# epoch 0 loss: 0.6003: 100%|██████████| 1001/1001 [26:28<00:00,  1.59s/it]\n",
    "# epoch 0 loss: 0.5525: 100%|██████████| 126/126 [01:02<00:00,  2.01it/s]\n",
    "# (array([0, 1]), array([1346, 2658]))\n",
    "# (array([0, 1]), array([2000, 2004]))\n",
    "# validation multi-class accuracy = 0.7223\n",
    "# epoch 1 loss: 0.5661: 100%|██████████| 1001/1001 [26:34<00:00,  1.59s/it]\n",
    "# epoch 1 loss: 0.5421: 100%|██████████| 126/126 [01:01<00:00,  2.06it/s]\n",
    "# (array([0, 1]), array([1379, 2625]))\n",
    "# (array([0, 1]), array([2000, 2004]))\n",
    "# validation multi-class accuracy = 0.7365\n",
    "# epoch 2 loss: 0.5376: 100%|██████████| 1001/1001 [26:35<00:00,  1.59s/it]\n",
    "# epoch 2 loss: 0.5190: 100%|██████████| 126/126 [01:01<00:00,  2.06it/s]\n",
    "# (array([0, 1]), array([1406, 2598]))\n",
    "# (array([0, 1]), array([2000, 2004]))\n",
    "# validation multi-class accuracy = 0.7393\n",
    "\n",
    "\n",
    "# Training with 0 started\n",
    "# 15999 4018\n",
    "# epoch 0 loss: 0.5194: 100%|██████████| 1000/1000 [26:29<00:00,  1.59s/it]\n",
    "# epoch 0 loss: 0.6937: 100%|██████████| 126/126 [01:01<00:00,  2.06it/s]\n",
    "# (array([0, 1]), array([1546, 2472]))\n",
    "# (array([0, 1]), array([1953, 2065]))\n",
    "# validation multi-class accuracy = 0.6493\n",
    "# acc = 0.6493\n",
    "# recall = 0.7574\n",
    "# precision = 0.6327\n",
    "# epoch 1 loss: 0.4363: 100%|██████████| 1000/1000 [26:32<00:00,  1.59s/it]\n",
    "# epoch 1 loss: 0.8429: 100%|██████████| 126/126 [00:59<00:00,  2.13it/s]\n",
    "# (array([0, 1]), array([2741, 1277]))\n",
    "# (array([0, 1]), array([1953, 2065]))\n",
    "# validation multi-class accuracy = 0.6063\n",
    "# acc = 0.6063\n",
    "# recall = 0.4262\n",
    "# precision = 0.6891\n",
    "# epoch 2 loss: 0.3699: 100%|██████████| 1000/1000 [26:31<00:00,  1.59s/it]\n",
    "# epoch 2 loss: 0.8512: 100%|██████████| 126/126 [00:59<00:00,  2.13it/s]\n",
    "# (array([0, 1]), array([2135, 1883]))\n",
    "# (array([0, 1]), array([1953, 2065]))\n",
    "# validation multi-class accuracy = 0.6237\n",
    "# acc = 0.6237\n",
    "# recall = 0.5898\n",
    "# precision = 0.6468\n",
    "# epoch 3 loss: 0.3070: 100%|██████████| 1000/1000 [26:30<00:00,  1.59s/it]\n",
    "# epoch 3 loss: 0.9448: 100%|██████████| 126/126 [00:59<00:00,  2.13it/s]\n",
    "# (array([0, 1]), array([2261, 1757]))\n",
    "# (array([0, 1]), array([1953, 2065]))\n",
    "# validation multi-class accuracy = 0.6401\n",
    "# acc = 0.6401\n",
    "# recall = 0.5753\n",
    "# precision = 0.6762\n",
    "# epoch 4 loss: 0.2391: 100%|██████████| 1000/1000 [26:30<00:00,  1.59s/it]\n",
    "# epoch 4 loss: 1.2499: 100%|██████████| 126/126 [00:59<00:00,  2.13it/s]\n",
    "# (array([0, 1]), array([2371, 1647]))\n",
    "# (array([0, 1]), array([1953, 2065]))\n",
    "# validation multi-class accuracy = 0.6297\n",
    "# acc = 0.6297\n",
    "# recall = 0.5385\n",
    "# precision = 0.6752\n",
    "# epoch 5 loss: 0.1974: 100%|██████████| 1000/1000 [26:29<00:00,  1.59s/it]\n",
    "# epoch 5 loss: 1.4107: 100%|██████████| 126/126 [00:59<00:00,  2.13it/s]\n",
    "# (array([0, 1]), array([2810, 1208]))\n",
    "# (array([0, 1]), array([1953, 2065]))\n",
    "# validation multi-class accuracy = 0.5941\n",
    "# acc = 0.5941\n",
    "# recall = 0.3976\n",
    "# precision = 0.6796\n",
    "# epoch 6 loss: 0.1483: 100%|██████████| 1000/1000 [26:29<00:00,  1.59s/it]\n",
    "# epoch 6 loss: 1.4747: 100%|██████████| 126/126 [00:59<00:00,  2.13it/s]\n",
    "# (array([0, 1]), array([2737, 1281]))\n",
    "# (array([0, 1]), array([1953, 2065]))\n",
    "# validation multi-class accuracy = 0.5978\n",
    "# acc = 0.5978\n",
    "# recall = 0.4189\n",
    "# precision = 0.6753\n",
    "# epoch 7 loss: 0.1342: 100%|██████████| 1000/1000 [26:29<00:00,  1.59s/it]\n",
    "# epoch 7 loss: 1.6187: 100%|██████████| 126/126 [00:59<00:00,  2.13it/s]\n",
    "# (array([0, 1]), array([2729, 1289]))\n",
    "# (array([0, 1]), array([1953, 2065]))\n",
    "# validation multi-class accuracy = 0.6023\n",
    "# acc = 0.6023\n",
    "# recall = 0.4252\n",
    "# precision = 0.6811\n",
    "\n",
    "\n",
    "# Training with 0 started\n",
    "# 16001 4016\n",
    "# epoch 0 loss: 0.5603: 100%|██████████| 1001/1001 [26:31<00:00,  1.59s/it]\n",
    "# epoch 0 loss: 0.6357: 100%|██████████| 126/126 [01:01<00:00,  2.06it/s]\n",
    "# (array([0, 1]), array([2207, 1809]))\n",
    "# (array([0, 1]), array([1974, 2042]))\n",
    "# validation multi-class accuracy = 0.6536\n",
    "# acc = 0.6536\n",
    "# recall = 0.6024\n",
    "# precision = 0.6799\n",
    "# epoch 1 loss: 0.5130: 100%|██████████| 1001/1001 [26:33<00:00,  1.59s/it]\n",
    "# epoch 1 loss: 0.7619: 100%|██████████| 126/126 [00:59<00:00,  2.11it/s]\n",
    "# (array([0, 1]), array([2612, 1404]))\n",
    "# (array([0, 1]), array([1974, 2042]))\n",
    "# validation multi-class accuracy = 0.6350\n",
    "# acc = 0.6350\n",
    "# recall = 0.4848\n",
    "# precision = 0.7051\n",
    "# epoch 2 loss: 0.4182: 100%|██████████| 1001/1001 [27:01<00:00,  1.62s/it]\n",
    "# epoch 2 loss: 0.8542: 100%|██████████| 126/126 [01:01<00:00,  2.05it/s]\n",
    "# (array([0, 1]), array([2494, 1522]))\n",
    "# (array([0, 1]), array([1974, 2042]))\n",
    "# validation multi-class accuracy = 0.6434\n",
    "# acc = 0.6434\n",
    "# recall = 0.5220\n",
    "# precision = 0.7004\n",
    "# epoch 3 loss: 0.3825: 100%|██████████| 1001/1001 [27:07<00:00,  1.63s/it]\n",
    "# epoch 3 loss: 0.9308: 100%|██████████| 126/126 [01:00<00:00,  2.09it/s]\n",
    "# (array([0, 1]), array([2302, 1714]))\n",
    "# (array([0, 1]), array([1974, 2042]))\n",
    "# validation multi-class accuracy = 0.6409\n",
    "# acc = 0.6409\n",
    "# recall = 0.5666\n",
    "# precision = 0.6750\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training with 0 started\n",
    "# 15996 4021\n",
    "# epoch 0 loss: 0.4292: 100%|██████████| 1000/1000 [26:58<00:00,  1.62s/it]\n",
    "# epoch 0 loss: 0.6624: 100%|██████████| 126/126 [01:02<00:00,  2.01it/s]\n",
    "# (array([0, 1]), array([2140, 1881]))\n",
    "# (array([0, 1]), array([2047, 1974]))\n",
    "# validation multi-class accuracy = 0.6481\n",
    "# recall = 0.6180\n",
    "# precision = 0.6486\n",
    "# epoch 1 loss: 0.2773: 100%|██████████| 1000/1000 [27:14<00:00,  1.63s/it]\n",
    "# epoch 1 loss: 0.8931: 100%|██████████| 126/126 [01:00<00:00,  2.09it/s]\n",
    "# (array([0, 1]), array([2835, 1186]))\n",
    "# (array([0, 1]), array([2047, 1974]))\n",
    "# validation multi-class accuracy = 0.5951\n",
    "# recall = 0.3880\n",
    "# precision = 0.6459\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training with 0 started\n",
    "# 16005 4012\n",
    "# epoch 0 loss: 0.5832: 100%|██████████| 1001/1001 [27:16<00:00,  1.63s/it]\n",
    "# epoch 0 loss: 0.6006: 100%|██████████| 126/126 [01:05<00:00,  1.92it/s]\n",
    "# (array([0, 1]), array([1140, 2872]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6852\n",
    "# recall = 0.9073\n",
    "# precision = 0.6240\n",
    "# epoch 1 loss: 0.5595: 100%|██████████| 1001/1001 [27:22<00:00,  1.64s/it]\n",
    "# epoch 1 loss: 0.5865: 100%|██████████| 126/126 [01:04<00:00,  1.95it/s]\n",
    "# (array([0, 1]), array([1668, 2344]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6837\n",
    "# recall = 0.7722\n",
    "# precision = 0.6506\n",
    "# epoch 2 loss: 0.5249: 100%|██████████| 1001/1001 [27:23<00:00,  1.64s/it]\n",
    "# epoch 2 loss: 0.5920: 100%|██████████| 126/126 [01:04<00:00,  1.96it/s]\n",
    "# (array([0, 1]), array([1589, 2423]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6825\n",
    "# recall = 0.7909\n",
    "# precision = 0.6447\n",
    "# epoch 3 loss: 0.4903: 100%|██████████| 1001/1001 [27:24<00:00,  1.64s/it]\n",
    "# epoch 3 loss: 0.5893: 100%|██████████| 126/126 [01:04<00:00,  1.95it/s]\n",
    "# (array([0, 1]), array([1830, 2182]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.7006\n",
    "# recall = 0.7484\n",
    "# precision = 0.6774\n",
    "# epoch 4 loss: 0.4799: 100%|██████████| 1001/1001 [27:26<00:00,  1.64s/it]\n",
    "# epoch 4 loss: 0.6795: 100%|██████████| 126/126 [01:05<00:00,  1.93it/s]\n",
    "# (array([0, 1]), array([1605, 2407]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6934\n",
    "# recall = 0.7980\n",
    "# precision = 0.6548\n",
    "# epoch 5 loss: 0.4500: 100%|██████████| 1001/1001 [27:18<00:00,  1.64s/it]\n",
    "# epoch 5 loss: 0.6719: 100%|██████████| 126/126 [01:03<00:00,  1.98it/s]\n",
    "# (array([0, 1]), array([1842, 2170]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6897\n",
    "# recall = 0.7342\n",
    "# precision = 0.6682\n",
    "# epoch 6 loss: 0.4287: 100%|██████████| 1001/1001 [27:21<00:00,  1.64s/it]\n",
    "# epoch 6 loss: 0.6843: 100%|██████████| 126/126 [01:03<00:00,  1.98it/s]\n",
    "# (array([0, 1]), array([2006, 2006]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6907\n",
    "# recall = 0.6937\n",
    "# precision = 0.6830\n",
    "# epoch 7 loss: 0.4077: 100%|██████████| 1001/1001 [27:20<00:00,  1.64s/it]\n",
    "# epoch 7 loss: 0.7017: 100%|██████████| 126/126 [01:03<00:00,  1.98it/s]\n",
    "# (array([0, 1]), array([1846, 2166]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6947\n",
    "# recall = 0.7382\n",
    "# precision = 0.6731\n",
    "# epoch 8 loss: 0.3889: 100%|██████████| 1001/1001 [27:19<00:00,  1.64s/it]\n",
    "# epoch 8 loss: 0.7242: 100%|██████████| 126/126 [01:05<00:00,  1.93it/s]\n",
    "# (array([0, 1]), array([1918, 2094]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6937\n",
    "# recall = 0.7190\n",
    "# precision = 0.6781\n",
    "# epoch 9 loss: 0.3869: 100%|██████████| 1001/1001 [27:16<00:00,  1.64s/it]\n",
    "# epoch 9 loss: 0.7539: 100%|██████████| 126/126 [01:04<00:00,  1.97it/s]\n",
    "# (array([0, 1]), array([2176, 1836]))\n",
    "# (array([0, 1]), array([2037, 1975]))\n",
    "# validation multi-class accuracy = 0.6837\n",
    "# recall = 0.6435\n",
    "# precision = 0.6923\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training with 0 started\n",
    "# 16003 4014\n",
    "# epoch 0 loss: 0.5466: 100%|██████████| 1001/1001 [27:09<00:00,  1.63s/it]\n",
    "# epoch 0 loss: 0.6560: 100%|██████████| 126/126 [01:06<00:00,  1.89it/s]\n",
    "# (array([0, 1]), array([1868, 2146]))\n",
    "# (array([0, 1]), array([2047, 1967]))\n",
    "# validation multi-class accuracy = 0.6425\n",
    "# recall = 0.6807\n",
    "# precision = 0.6240\n",
    "# epoch 1 loss: 0.4770: 100%|██████████| 1001/1001 [27:25<00:00,  1.64s/it]\n",
    "# epoch 1 loss: 0.6956: 100%|██████████| 126/126 [01:11<00:00,  1.76it/s]\n",
    "# (array([0, 1]), array([2083, 1931]))\n",
    "# (array([0, 1]), array([2047, 1967]))\n",
    "# validation multi-class accuracy = 0.6587\n",
    "# recall = 0.6426\n",
    "# precision = 0.6546\n",
    "\n",
    "\n",
    "#################################### EfficientNet-B4\n",
    "\n",
    "# Training with 0 started\n",
    "# 15992 4025\n",
    "# epoch 0 loss: 0.6061: 100%|██████████| 1000/1000 [27:14<00:00,  1.63s/it]\n",
    "# epoch 0 loss: 0.5896: 100%|██████████| 126/126 [01:06<00:00,  1.91it/s]\n",
    "# (array([0, 1]), array([1317, 2708]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6678\n",
    "# recall = 0.8711\n",
    "# precision = 0.5942\n",
    "# epoch 1 loss: 0.5720: 100%|██████████| 1000/1000 [27:26<00:00,  1.65s/it]\n",
    "# epoch 1 loss: 0.5771: 100%|██████████| 126/126 [01:05<00:00,  1.92it/s]\n",
    "# (array([0, 1]), array([1828, 2197]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6989\n",
    "# recall = 0.7666\n",
    "# precision = 0.6445\n",
    "# epoch 2 loss: 0.5468: 100%|██████████| 1000/1000 [27:26<00:00,  1.65s/it]\n",
    "# epoch 2 loss: 0.5787: 100%|██████████| 126/126 [01:04<00:00,  1.97it/s]\n",
    "# (array([0, 1]), array([1512, 2513]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6860\n",
    "# recall = 0.8381\n",
    "# precision = 0.6160\n",
    "# epoch 3 loss: 0.5159: 100%|██████████| 1000/1000 [27:25<00:00,  1.65s/it]\n",
    "# epoch 3 loss: 0.6714: 100%|██████████| 126/126 [01:03<00:00,  1.98it/s]\n",
    "# (array([0, 1]), array([2118, 1907]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6820\n",
    "# recall = 0.6697\n",
    "# precision = 0.6487\n",
    "# epoch 4 loss: 0.5076: 100%|██████████| 1000/1000 [27:27<00:00,  1.65s/it]\n",
    "# epoch 4 loss: 0.6022: 100%|██████████| 126/126 [01:04<00:00,  1.97it/s]\n",
    "# (array([0, 1]), array([1568, 2457]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6681\n",
    "# recall = 0.8035\n",
    "# precision = 0.6040\n",
    "# epoch 5 loss: 0.4765: 100%|██████████| 1000/1000 [27:08<00:00,  1.63s/it]\n",
    "# epoch 5 loss: 0.6339: 100%|██████████| 126/126 [01:01<00:00,  2.04it/s]\n",
    "# (array([0, 1]), array([2152, 1873]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6999\n",
    "# recall = 0.6800\n",
    "# precision = 0.6706\n",
    "# epoch 6 loss: 0.4565: 100%|██████████| 1000/1000 [26:33<00:00,  1.59s/it]\n",
    "# epoch 6 loss: 0.6661: 100%|██████████| 126/126 [01:02<00:00,  2.03it/s]\n",
    "# (array([0, 1]), array([2145, 1880]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6698\n",
    "# recall = 0.6492\n",
    "# precision = 0.6378\n",
    "# epoch 7 loss: 0.4405: 100%|██████████| 1000/1000 [27:04<00:00,  1.62s/it]\n",
    "# epoch 7 loss: 0.6883: 100%|██████████| 126/126 [01:03<00:00,  1.97it/s]\n",
    "# (array([0, 1]), array([2228, 1797]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6800\n",
    "# recall = 0.6378\n",
    "# precision = 0.6555\n",
    "# epoch 8 loss: 0.4142: 100%|██████████| 1000/1000 [27:23<00:00,  1.64s/it]\n",
    "# epoch 8 loss: 0.7311: 100%|██████████| 126/126 [01:04<00:00,  1.96it/s]\n",
    "# (array([0, 1]), array([2404, 1621]))\n",
    "# (array([0, 1]), array([2178, 1847]))\n",
    "# validation multi-class accuracy = 0.6706\n",
    "# recall = 0.5799\n",
    "# precision = 0.6607\n",
    "\n",
    "\n",
    "\n",
    "#################################### EfficientNet-B6\n",
    "# Training with 0 started\n",
    "# 15999 4018\n",
    "# epoch 0 loss: 0.6169: 100%|██████████| 2000/2000 [50:08<00:00,  1.50s/it]\n",
    "# epoch 0 loss: 0.5906: 100%|██████████| 252/252 [01:54<00:00,  2.21it/s]\n",
    "# (array([0, 1]), array([1424, 2594]))\n",
    "# (array([0, 1]), array([2056, 1962]))\n",
    "# validation multi-class accuracy = 0.6909\n",
    "# recall = 0.8445\n",
    "# precision = 0.6388\n",
    "# epoch 1 loss: 0.5837: 100%|██████████| 2000/2000 [50:17<00:00,  1.51s/it]\n",
    "# epoch 1 loss: 0.6239: 100%|██████████| 252/252 [01:51<00:00,  2.25it/s]\n",
    "# (array([0, 1]), array([1624, 2394]))\n",
    "# (array([0, 1]), array([2056, 1962]))\n",
    "# validation multi-class accuracy = 0.6789\n",
    "# recall = 0.7813\n",
    "# precision = 0.6404\n",
    "# epoch 2 loss: 0.5587: 100%|██████████| 2000/2000 [50:13<00:00,  1.51s/it]\n",
    "# epoch 2 loss: 0.6101: 100%|██████████| 252/252 [01:51<00:00,  2.25it/s]\n",
    "# (array([0, 1]), array([1475, 2543]))\n",
    "# (array([0, 1]), array([2056, 1962]))\n",
    "# validation multi-class accuracy = 0.6782\n",
    "# recall = 0.8186\n",
    "# precision = 0.6315\n",
    "# Training with 1 started\n",
    "# 16028 3989\n",
    "# epoch 0 loss: 0.6161: 100%|██████████| 2004/2004 [49:33<00:00,  1.48s/it]\n",
    "# epoch 0 loss: 0.6110: 100%|██████████| 250/250 [01:50<00:00,  2.26it/s]\n",
    "# (array([0, 1]), array([1691, 2298]))\n",
    "# (array([0, 1]), array([1950, 2039]))\n",
    "# validation multi-class accuracy = 0.6658\n",
    "# recall = 0.7366\n",
    "# precision = 0.6536\n",
    "# epoch 1 loss: 0.5981: 100%|██████████| 2004/2004 [49:19<00:00,  1.48s/it]\n",
    "# epoch 1 loss: 0.6524: 100%|██████████| 250/250 [01:49<00:00,  2.29it/s]\n",
    "# (array([0, 1]), array([2348, 1641]))\n",
    "# (array([0, 1]), array([1950, 2039]))\n",
    "# validation multi-class accuracy = 0.6450\n",
    "# recall = 0.5552\n",
    "# precision = 0.6898\n",
    "# epoch 2 loss: 0.5705: 100%|██████████| 2004/2004 [49:18<00:00,  1.48s/it]\n",
    "# epoch 2 loss: 0.8050: 100%|██████████| 250/250 [01:49<00:00,  2.29it/s]\n",
    "# (array([0, 1]), array([2660, 1329]))\n",
    "# (array([0, 1]), array([1950, 2039]))\n",
    "# validation multi-class accuracy = 0.6340\n",
    "# recall = 0.4679\n",
    "# precision = 0.7178\n",
    "# Training with 2 started\n",
    "# 16047 3970\n",
    "# epoch 0 loss: 0.6025: 100%|██████████| 2006/2006 [49:21<00:00,  1.48s/it]\n",
    "# epoch 0 loss: 0.7158: 100%|██████████| 249/249 [01:48<00:00,  2.29it/s]\n",
    "# (array([0, 1]), array([1974, 1996]))\n",
    "# (array([0, 1]), array([1940, 2030]))\n",
    "# validation multi-class accuracy = 0.6599\n",
    "# recall = 0.6591\n",
    "# precision = 0.6703\n",
    "# epoch 1 loss: 0.5745: 100%|██████████| 2006/2006 [49:23<00:00,  1.48s/it]\n",
    "# epoch 1 loss: 0.6577: 100%|██████████| 249/249 [01:48<00:00,  2.29it/s]\n",
    "# (array([0, 1]), array([1582, 2388]))\n",
    "# (array([0, 1]), array([1940, 2030]))\n",
    "# validation multi-class accuracy = 0.6680\n",
    "# recall = 0.7635\n",
    "# precision = 0.6491\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
