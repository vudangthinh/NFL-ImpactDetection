{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, \"timm-efficientdet-pytorch\")\n",
    "sys.path.insert(0, \"../efficientdet-pytorch-master\")\n",
    "sys.path.insert(0, \"../omegaconf\")\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
    "from effdet.efficientdet import HeadNet\n",
    "from tqdm import tqdm\n",
    "from IPython.core.debugger import set_trace\n",
    "import warnings\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "IMG_H = 1024\n",
    "IMG_W = 1024\n",
    "gpu_id = 'cuda:1'\n",
    "device = torch.device(gpu_id)\n",
    "# DETECTION_THRESHOLD = 0.4\n",
    "# DETECTOR_FILTERING_THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_labels = pd.read_csv('/home/thinh/nfl/train_labels.csv').fillna(0)\n",
    "video_labels = video_labels[video_labels['frame'] != 0].reset_index(drop=True)\n",
    "video_labels['video_name'] = video_labels['video'].apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n",
    "video_labels['image_name'] = video_labels['video'].str.replace('.mp4', '') + '_' + video_labels['frame'].astype(str) + '.png'\n",
    "\n",
    "video_valid = ['57583_000082', '57586_004152', '57911_000147', '57997_003691', '57680_002206', '58095_004022', '57906_000718', '58005_001254', '57679_003316', '58103_003494', '57998_002181', '58048_000086']\n",
    "images_valid = video_labels[ video_labels.video_name.isin(video_valid)].image_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.Resize(height=IMG_H, width=IMG_W, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ROOT_PATH = 'train_images'\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, image_ids, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'/home/thinh/nfl/{TRAIN_ROOT_PATH}/{image_id}', cv2.IMREAD_COLOR).copy().astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "        return image, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d6')\n",
    "\n",
    "    # config.num_classes = 2\n",
    "    config.image_size = [IMG_H, IMG_W]\n",
    "    config.norm_kwargs=dict(eps=.001, momentum=.01)\n",
    "\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=gpu_id)\n",
    "    \n",
    "    net.reset_head(num_classes=2)\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    net = DetBenchPredict(net)\n",
    "    net.eval()\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetRetriever(\n",
    "    image_ids=images_valid,\n",
    "    transforms=get_valid_transforms()\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(net, images):\n",
    "    images = torch.stack(images).to(device).float()\n",
    "    box_list = []\n",
    "    score_list = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        target_res = {}\n",
    "        target_res['img_scale'] = torch.tensor([1]*images.shape[0]).float().to(device)\n",
    "        target_res['img_size'] = torch.tensor(images.shape[2:]).repeat(images.shape[0], 1).to(device)\n",
    "        \n",
    "        det = net(images, target_res)        \n",
    "        \n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "            scores = det[i].detach().cpu().numpy()[:,4]   \n",
    "            label = det[i].detach().cpu().numpy()[:,5]\n",
    "            # useing only label = 2\n",
    "            indexes = np.where(label == 2)[0]\n",
    "#             indexes = np.where((scores > score_threshold) & (label == 2))[0]\n",
    "#             boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "#             boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "            box_list.append(boxes[indexes])\n",
    "            score_list.append(scores[indexes])\n",
    "    return box_list, score_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_name):\n",
    "    net = load_net(f'/home/thinh/nfl/effdet5-models/tito-1024/{model_name}.bin')\n",
    "    \n",
    "    \n",
    "    result_image_ids = []\n",
    "    results_boxes = []\n",
    "    results_scores = []\n",
    "    for images, image_ids in tqdm(data_loader):\n",
    "        box_list, score_list = make_predictions(net, images)\n",
    "        for i, image in enumerate(images):\n",
    "            boxes = box_list[i]\n",
    "            scores = score_list[i]\n",
    "            image_id = image_ids[i]\n",
    "            boxes[:, 0] = (boxes[:, 0] * 1280 / IMG_W)\n",
    "            boxes[:, 1] = (boxes[:, 1] * 720 / IMG_H)\n",
    "            boxes[:, 2] = (boxes[:, 2] * 1280 / IMG_W)\n",
    "            boxes[:, 3] = (boxes[:, 3] * 720 / IMG_H)\n",
    "            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "            boxes = boxes.astype(np.int32)\n",
    "            boxes[:, 0] = boxes[:, 0].clip(min=0, max=1280-1)\n",
    "            boxes[:, 2] = boxes[:, 2].clip(min=0, max=1280-1)\n",
    "            boxes[:, 1] = boxes[:, 1].clip(min=0, max=720-1)\n",
    "            boxes[:, 3] = boxes[:, 3].clip(min=0, max=720-1)\n",
    "\n",
    "    #         zero_rows = np.where(boxes[:, 2:] == 0)[0]\n",
    "    #         boxes = np.delete(boxes, zero_rows, axis=0)\n",
    "    #         scores = np.delete(scores, zero_rows, axis=0)\n",
    "\n",
    "    #         if boxes.shape[0] >= 2:\n",
    "            result_image_ids += [image_id]*len(boxes)\n",
    "            results_boxes.append(boxes)\n",
    "            results_scores.append(scores)\n",
    "            \n",
    "            \n",
    "    box_df = pd.DataFrame(np.concatenate(results_boxes), columns=['left', 'top', 'width', 'height'])\n",
    "    test_df = pd.DataFrame({'score':np.concatenate(results_scores), 'image_name':result_image_ids})\n",
    "    test_df = pd.concat([test_df, box_df], axis=1)\n",
    "    # test_df = test_df[test_df.scores > DETECTOR_FILTERING_THRESHOLD]\n",
    "    print(test_df.shape)\n",
    "    \n",
    "    \n",
    "    #gameKey,playID,view,video,frame,left,width,top,height\n",
    "    #57590,3607,Endzone,57590_003607_Endzone.mp4,1,1,1,1,1\n",
    "    test_df['gameKey'] = test_df.image_name.str.split('_').str[0].astype(int)\n",
    "    test_df['playID'] = test_df.image_name.str.split('_').str[1].astype(int)\n",
    "    test_df['view'] = test_df.image_name.str.split('_').str[2]\n",
    "    test_df['frame'] = test_df.image_name.str.split('_').str[3].str.replace('.png','').astype(int)\n",
    "    test_df['video'] = test_df.image_name.str.rsplit('_',1).str[0] + '.mp4'\n",
    "    test_df = test_df[[\"gameKey\",\"playID\",\"view\",\"video\",\"frame\",\"left\",\"width\",\"top\",\"height\",\"score\"]]\n",
    "#     test_df\n",
    "\n",
    "    test_df.to_csv(f'/home/thinh/nfl/effdet5-models/tito-1024/{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [35:36<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230648, 6)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'tito-checkpoint-D6-1024-A1-epoch030-fold0-gcp'\n",
    "predict(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in glob(\"/home/thinh/nfl/effdet5-models/tito-512/tito-checkpoint-512-deim-epoch*\"):\n",
    "#     model_name = os.path.basename(file).split(\".\")[0]\n",
    "#     print(model_name)\n",
    "#     predict(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
